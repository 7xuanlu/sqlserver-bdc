{
    "metadata": {
        "kernelspec": {
            "name": "powershell",
            "display_name": "PowerShell"
        },
        "language_info": {
            "name": "powershell",
            "codemirror_mode": "shell",
            "mimetype": "text/x-sh",
            "file_extension": ".ps1"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "<img src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/solutions-microsoft-logo-small.png?raw=true\" alt=\"Microsoft\">\r\n",
                "<br>\r\n",
                "\r\n",
                "# **SQL Server 2019 big data cluster Tutorial**\r\n",
                "## **00 - Scenario Overview and System Setup**\r\n",
                "\r\n",
                "In this set of tutorials you'll work with an end-to-end scenario that uses SQL Server 2019's big data clusters to solve real-world problems. \r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "d495f8be-74c3-4658-b897-ad69e6ed88ac"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Wide World Importers**\r\n",
                "\r\n",
                "Wide World Importers (WWI) is a traditional brick and mortar business that makes specialty items for other companies to use in their products. They design, sell and ship these products worldwide.\r\n",
                "\r\n",
                "WWI corporate has now added a new partnership with a company called \"AdventureWorks\", which sells bicycles both online and in-store. The AdventureWorks company has asked WWI to produce super-hero themed baskets, seats and other bicycle equipment for a new line of bicycles. WWI corporate has asked the IT department to develop a pilot program with these goals: \r\n",
                "\r\n",
                "- Integrate the large amounts of data from the AdventureWorks company including customers, products and sales\r\n",
                "- Allow a cross-selling strategy so that current WWI customers and AdventureWorks customers see their information without having to re-enter it\r\n",
                "- Incorporate their online sales information for deeper analysis\r\n",
                "- Provide a historical data set so that the partnership can be evaluated\r\n",
                "- Ensure this is a \"framework\" approach, so that it can be re-used with other partners\r\n",
                "\r\n",
                "WWI has a typical N-Tier application that provides a series of terminals, a Business Logic layer, and a Database back-end. They use on-premises systems, and are interested in linking these to the cloud. \r\n",
                "\r\n",
                "In this series of tutorials, you will build a solution using the scale-out features of SQL Server 2019, Data Virtualization, Data Marts, and the Data Lake features. "
            ],
            "metadata": {
                "azdata_cell_guid": "3815241f-e81e-4cf1-a48e-c6e67b0ccf7c"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Running these Tutorials**\r\n",
                "\r\n",
                "- You can read through the output of these completed tutorials if you wish - or:\r\n",
                "\r\n",
                "- You can follow along with the steps you see in these tutorials by copying the code into a SQL Query window and Spark Notebook using the Azure Data Studio tool, or you can click here to download these Jupyter Notebooks and run them in Azure Data Studio for a hands-on experience.\r\n",
                " \r\n",
                "- If you would like to run the tutorials, you'll need a SQL Server 2019 big data cluster and the client tools installed. If you want to set up your own cluster, <a href=\"https://docs.microsoft.com/en-us/sql/big-data-cluster/deploy-get-started?view=sqlallproducts-allversions\" target=\"_blank\">click this reference and follow the steps you see there for the server and tools you need</a>.\r\n",
                "\r\n",
                "- You will need to have the following: \r\n",
                "    - Your **Knox Password**\r\n",
                "    - The **Knox IP Address**\r\n",
                "    - The `sa` **Username** and **Password** to your Master Instance\r\n",
                "    - The **IP address** to the SQL Server big data cluster Master Instance \r\n",
                "    - The **name** of your big data cluster\r\n",
                "\r\n",
                "For a complete workshop on SQL Server 2019's big data clusters, <a href=\"https://github.com/Microsoft/sqlworkshops/tree/master/sqlserver2019bigdataclusters\" target=\"_blank\">check out this resource</a>."
            ],
            "metadata": {
                "azdata_cell_guid": "1c3e4b5e-fef4-43ef-a4e3-aa33fe99e25d"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Copy Database backups to the SQL Server 2019 big data cluster Master Instance**\r\n",
                "\r\n",
                "The first step for the solution is to copy the database backups from WWI from their location on the cloud and then up to your cluster. \r\n",
                "\r\n",
                "These commands use the `curl` program to pull the files down. [You can read more about curl here](https://curl.haxx.se/). \r\n",
                "\r\n",
                "The next set of commands use the `kubectl` command to copy the files from where you downloaded them to the data directory of the SQL Server 2019 bdc Master Instance. [You can read more about kubectl here](https://kubernetes.io/docs/reference/kubectl/overview/). \r\n",
                "\r\n",
                "Note that you will need to replace the section of the script marked with `<ReplaceWithClusterName>` with the name of your SQL Server 2019 bdc. (It does not need single or double quotes, just the letters of your cluster name.)\r\n",
                "\r\n",
                "Notice also that these commands assume a `c:\\temp` location, if you want to use another drive or directory, edit accordingly.\r\n",
                "\r\n",
                "Once you have edited these commands, you can open a Command Prompt *(not PowerShell)* on your system and copy and paste each block, one at a time and run them there, observing the output.\r\n",
                "\r\n",
                "In the next tutorial you will restore these databases on the Master Instance."
            ],
            "metadata": {
                "azdata_cell_guid": "5220c555-f819-409e-b206-de9a2dd6d434"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# REM Create a temporary directory for the files\r\n",
                "md c:\\temp\r\n",
                "cd c:\\temp\r\n",
                "\r\n",
                "# REM Get the database backups\r\n",
                "curl \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/WWI.bak\" -o c:\\temp\\WWI.bak\r\n",
                "curl \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/AdventureWorks.bak\" -o c:\\temp\\AdventureWorks.bak\r\n",
                "curl \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/AdventureWorksDW.bak\" -o c:\\temp\\AdventureWorksDW.bak\r\n",
                "curl \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/Analysis.bak\" -o c:\\temp\\Analysis.bak\r\n",
                "curl \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/sales.bak\" -o c:\\temp\\sales.bak\r\n",
                "curl \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/NYC.bak\" -o c:\\temp\\NYC.bak\r\n",
                "curl \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/WWIDW.bak\" -o c:\\temp\\WWIDW.bak\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "3e1f2304-cc0a-4e0e-96e2-333401b52036",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "# REM Copy the backups to the data location on the SQL Server Master Instance\r\n",
                "cd c:\\temp\r\n",
                "kubectl cp WWI.bak mssql-cluster/master-0:/var/opt/mssql/data -c mssql-server -n K8s4sqlbdc\r\n",
                "kubectl cp WWIDW.bak mssql-cluster/master-0:/var/opt/mssql/data -c mssql-server -n K8s4sqlbdc\r\n",
                "kubectl cp sales.bak mssql-cluster/master-0:/var/opt/mssql/data -c mssql-server -n K8s4sqlbdc\r\n",
                "kubectl cp analysis.bak mssql-cluster/master-0:/var/opt/mssql/data -c mssql-server -n K8s4sqlbdc\r\n",
                "kubectl cp AdventureWorks.bak mssql-cluster/master-0:/var/opt/mssql/data -c mssql-server -n K8s4sqlbdc\r\n",
                "kubectl cp AdventureWorksDW.bak mssql-cluster/master-0:/var/opt/mssql/data -c mssql-server -n K8s4sqlbdc\r\n",
                "kubectl cp NYC.bak mssql-cluster/master-0:/var/opt/mssql/data -c mssql-server -n K8s4sqlbdc\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "19106890-7c6c-4631-9acc-3dda4d2a50ab"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": ""
                }
            ],
            "execution_count": 4
        },
        {
            "cell_type": "markdown",
            "source": [
                "Check if the data is transfered successfully"
            ],
            "metadata": {
                "azdata_cell_guid": "407b8015-0820-4e3d-8607-96db43d9c64d"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# List all the files downloaded in master instance\r\n",
                "kubectl exec master-0 -n mssql-cluster -- ls -la /var/opt/mssql/data"
            ],
            "metadata": {
                "azdata_cell_guid": "d914c707-5c2e-4c20-b600-b8c264779b61"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Defaulting container name to mssql-server.\nUse 'kubectl describe pod/master-0 -n mssql-cluster' to see all of the containers in this pod.\ntotal 4030800\ndrwxr-xr-x 2 root root      4096 Feb 14 08:02 .\ndrwxr-xr-x 6 root root      4096 Dec 30 12:09 ..\n-rw-rw-rw- 1 root root  50286592 Feb 14 03:29 AdventureWorks.bak\n-rw-r----- 1 root root 276824064 Feb 14 07:34 AdventureWorks2017.mdf\n-rw-r----- 1 root root  75497472 Feb 14 07:54 AdventureWorks2017_log.ldf\n-rw-rw-rw- 1 root root  23436800 Feb 14 03:30 AdventureWorksDW.bak\n-rw-r----- 1 root root 142606336 Feb 14 07:54 AdventureWorksDW.mdf\n-rw-r----- 1 root root  75497472 Feb 14 07:54 AdventureWorksDW_log.ldf\n-rw-r----- 1 root root   8388608 Jan 18 10:46 DWConfiguration.mdf\n-rw-r----- 1 root root   8388608 Feb 14 07:54 DWConfiguration_log.ldf\n-rw-r----- 1 root root 524288000 Dec 30 12:14 DWDiagnostics.mdf\n-rw-r----- 1 root root  75497472 Feb 14 07:54 DWDiagnostics_log.ldf\n-rw-r----- 1 root root   8388608 Jan 13 06:14 DWQueue.mdf\n-rw-r----- 1 root root   8388608 Feb 14 07:54 DWQueue_log.ldf\n-rw-r----- 1 root root       256 Dec 30 12:08 Entropy.bin\n-rw-rw-rw- 1 root root 101834752 Feb 14 03:34 NYC.bak\n-rw-r----- 1 root root 142606336 Feb 14 07:34 NYC.mdf\n-rw-r----- 1 root root 142606336 Feb 14 07:54 NYC_0.ldf\n-rw-rw-rw- 1 root root 490479616 Feb 14 08:04 WWI.bak\n-rw-rw-rw- 1 root root 250548224 Feb 14 03:50 WWIDW.bak\n-rw-rw-rw- 1 root root 245346304 Feb 14 03:26 analysis.bak\n-rw-r----- 1 root root   8388608 Feb 14 07:54 analysis.ldf\n-rw-r----- 1 root root 366608384 Feb 14 07:33 analysis.mdf\n-rw-r----- 1 root root   4653056 Feb 14 07:34 master.mdf\n-rw-r----- 1 root root   2097152 Feb 14 07:34 mastlog.ldf\n-rw-r----- 1 root root   8388608 Dec 30 12:14 model.mdf\n-rw-r----- 1 root root  15466496 Jan  7 09:19 model_msdbdata.mdf\n-rw-r----- 1 root root    786432 Jan  7 09:19 model_msdblog.ldf\n-rw-r----- 1 root root   2359296 Jan  7 09:19 model_replicatedmaster.ldf\n-rw-r----- 1 root root   4653056 Dec 30 12:09 model_replicatedmaster.mdf\n-rw-r----- 1 root root   8388608 Jan 16 06:13 modellog.ldf\n-rw-r----- 1 root root  15466496 Feb 14 07:34 msdbdata.mdf\n-rw-r----- 1 root root    786432 Feb 14 07:34 msdblog.ldf\n-rw------- 1 root root  51150848 Feb 14 04:00 sales.bak\n-rw-r----- 1 root root  75497472 Jan 30 03:32 tempdb.mdf\n-rw-r----- 1 root root  75497472 Jan 21 03:10 tempdb2.ndf\n-rw-r----- 1 root root  75497472 Jan 21 03:10 tempdb3.ndf\n-rw-r----- 1 root root  75497472 Jan 21 03:10 tempdb4.ndf\n-rw-r----- 1 root root  75497472 Jan 21 03:10 tempdb5.ndf\n-rw-r----- 1 root root  75497472 Jan 21 03:10 tempdb6.ndf\n-rw-r----- 1 root root  75497472 Jan 21 03:10 tempdb7.ndf\n-rw-r----- 1 root root  75497472 Jan 21 03:10 tempdb8.ndf\n-rw-r----- 1 root root   8388608 Feb 14 07:33 templog.ldf\n-rw-r----- 1 root root   8388608 Feb 14 07:54 tpcxbb_1gb.ldf\n-rw-r----- 1 root root 366608384 Feb  7 12:22 tpcxbb_1gb.mdf\n"
                }
            ],
            "execution_count": 11
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Copy Exported Data to Storage Pool**\r\n",
                "\r\n",
                "Next, you'll download a few text files that will form the external data to be ingested into the Storage Pool HDFS store. In production environments, you have multiple options for moving data into HDFS, such as Spark Streaming or the Azure Data Factory.\r\n",
                "\r\n",
                "The first code block creates directories in the HDFS store. The second block downloads the source data from a web location. And in the final block, you'll copy the data from your local system to the SQL Server 2019 big data cluster Storage Pool.\r\n",
                "\r\n",
                "You need to replace the `<ReplaceWithHDFSGatewayPassword>`, `<ReplaceWithHDFSGatewayEndpoint>`, and potentially the drive letter and directory values with the appropriate information on your system. \r\n",
                "> (You can use **CTL-H** to open the Find and Replace dialog in the cell)"
            ],
            "metadata": {
                "azdata_cell_guid": "2c426b35-dc57-4dc8-819d-6642deb69110"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# REM Make the Directories in HDFS\r\n",
                "# Run below commands in terminal or cmd, not powershell\r\n",
                "curl -i -L -k -u root:admin#1234 -X PUT \"https://20.43.162.163:30443/gateway/default/webhdfs/v1/product_review_data?op=MKDIRS\"\r\n",
                "curl -i -L -k -u root:admin#1234 -X PUT \"https://20.43.162.163:30443/gateway/default/webhdfs/v1/partner_customers?op=MKDIRS\"\r\n",
                "curl -i -L -k -u root:admin#1234 -X PUT \"https://20.43.162.163:30443/gateway/default/webhdfs/v1/partner_products?op=MKDIRS\"\r\n",
                "curl -i -L -k -u root:admin#1234 -X PUT \"https://20.43.162.163:30443/gateway/default/webhdfs/v1/web_logs?op=MKDIRS\"\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "f2143d4e-6eb6-4bbc-864a-b417398adc21"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "# REM Get the textfiles \r\n",
                "# Run below commands in terminal or cmd, not powershell\r\n",
                "curl -G \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/product_reviews_sample.csv\" -o product_reviews.csv\r\n",
                "curl -G \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/customers.csv\" -o customers.csv\r\n",
                "curl -G \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/stockitemholdings.csv\" -o products.csv\r\n",
                "curl -G \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/web_clickstreams.csv\" -o web_clickstreams.csv\r\n",
                "curl -G \"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/training-formatted.csv\" -o training-formatted.csv\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "c8a74514-2e0d-4f3c-99dd-4c541c11e15e"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "# REM Copy the text files to the HDFS directories\r\n",
                "# Run below commands in terminal or cmd, not powershell\r\n",
                "curl -i -L -k -u root:admin#1234 -X PUT \"https://20.43.162.163:30443/gateway/default/webhdfs/v1/product_review_data/product_reviews.csv?op=create&overwrite=true\" -H \"Content-Type: application/octet-stream\" -T \"product_reviews.csv\"\r\n",
                "curl -i -L -k -u root:admin#1234 -X PUT \"https://20.43.162.163:30443/gateway/default/webhdfs/v1/partner_customers/customers.csv?op=create&overwrite=true\" -H \"Content-Type: application/octet-stream\" -T \"customers.csv\"\r\n",
                "curl -i -L -k -u root:admin#1234 -X PUT \"https://20.43.162.163:30443/gateway/default/webhdfs/v1/partner_products/products.csv?op=create&overwrite=true\" -H \"Content-Type: application/octet-stream\" -T \"products.csv\"\r\n",
                "curl -i -L -k -u root:admin#1234 -X PUT \"https://20.43.162.163:30443/gateway/default/webhdfs/v1/web_logs/web_clickstreams.csv?op=create&overwrite=true\" -H \"Content-Type: application/octet-stream\" -T \"web_clickstreams.csv\"\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "9c9e49ef-ef0d-47c4-92fd-b7e7bfa2d2f2"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Next Step: Working with the SQL Server 2019 big data cluster Master Instance\r\n",
                "\r\n",
                "Now you're ready to open the next Python Notebook - [bdc_tutorial_01.ipynb](bdc_tutorial_01.ipynb) - to learn how to work with the SQL Server 2019 bdc Master Instance."
            ],
            "metadata": {
                "azdata_cell_guid": "519aa112-47e0-443b-9b27-05fc02349b09"
            }
        }
    ]
}